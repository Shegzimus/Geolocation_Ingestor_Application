locals {
  data_lake_bucket = "gontrel_data_lake"
}

variable "project" {
  description = "Your GCP Project ID"
  default = "gontrel"
  type = string
}

variable "region" {
  description = "Region for GCP resources"
  default = "europe-west3"
  type = string
}



variable "gcs_credentials" {
  description = "Path to the gcs cred json file"
  default = "../airflow/.google/gcs/gcs_credentials.json"
  type = string
}

variable "storage_class" {
  description = "Storage class type for your bucket. Check official docs for more info."
  default = "STANDARD"
}

variable "restaurant_locations_wh" {
  description = "BigQuery Dataset that stores the restaurant location data extracted by the DFS Adaptive Search service"
  type = string
  default = "restaurant_locations_wh"
}

variable "tiktok_data_wh" {
  description = "BigQuery Dataset that stores the data generated by the TikTok API and the transcriber service"
  type = string
  default = "tiktok_data_wh"
}



# ------------------------------------------------------------------------------------------------------------------------------
# # VM Variables

variable "vm_credentials" {
  description = "Path to the vm cred json file"
  default = "../airflow/.google/compute/vm_credentials.json"
  type = string
}

variable "image" {
    description = "Machine Image"
    default = "ubuntu-2004-focal-v20250111"
}

variable "zone" {
  description = "Zone for compute resources"
  default = "europe-west3-a"
  type = string
}

variable "user"{
    description = "User for maching"
    default = "gontrel_user"
}

variable "ssh_key_file" {
  description = "Path to the SSH public key file"
  default     = "~/.ssh/gcp.pub" 

}